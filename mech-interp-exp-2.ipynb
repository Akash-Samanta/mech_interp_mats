{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6348120,"sourceType":"datasetVersion","datasetId":3655658}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\n# Set up model and data\nmodel = torchvision.models.resnet50(pretrained=True)\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Data preprocessing\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load ImageNet validation data\nval_dataset = datasets.ImageFolder('/kaggle/input/imagenet1k-val/imagenet-val', transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\ndef evaluate_model(model):\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    return 100. * correct / total\n\n# Get baseline accuracy\nprint(\"Computing baseline accuracy...\")\nbaseline_acc = evaluate_model(model)\nprint(f\"Baseline Accuracy: {baseline_acc:.2f}%\")\n\n# Collect all conv layers\nconv_layers = {}\nfor name, module in model.named_modules():\n    if isinstance(module, torch.nn.Conv2d):\n        conv_layers[name] = module\n\n# Hook \nactivations = {}\ndef get_activation(name):\n    def hook(model, input, output):\n        activations[name] = output.detach()\n    return hook\n\n\nhooks = []\nfor name, module in conv_layers.items():\n    hooks.append(module.register_forward_hook(get_activation(name)))\n\ndef compute_all_feature_importance():\n    feature_importance = {name: [] for name in conv_layers.keys()}\n    \n    with torch.no_grad():\n        for images, _ in tqdm(val_loader, desc=\"Computing importance for all layers\"):\n            images = images.to(device)\n            _ = model(images)\n            \n            # Process activations for all layers at once\n            for name in conv_layers.keys():\n                features = activations[name]  # [B, C, H, W]\n                mean_feature = features.mean(dim=1, keepdim=True)  # [B, 1, H, W]\n                channel_importance = (features - mean_feature) ** 2  # [B, C, H, W]\n                importance_scores = channel_importance.mean(dim=[0, 2, 3])  # [C]\n                feature_importance[name].append(importance_scores.cpu())\n    \n    # Process importance scores for all layers\n    importance_results = {}\n    for name in conv_layers.keys():\n        scores = torch.stack(feature_importance[name]).mean(dim=0)\n        normalized_scores = (scores - scores.min()) / (scores.max() - scores.min())\n        importance_results[name] = normalized_scores.numpy()\n    \n    return importance_results\n\ndef ablate_channels(model, layer_name, conv_layer, importance_scores, percent_to_ablate=10):\n    num_channels = len(importance_scores)\n    num_to_ablate = int(num_channels * percent_to_ablate / 100)\n    \n    # Get indices of top channels\n    top_channels = np.argsort(importance_scores)[-num_to_ablate:]\n    \n    # Create a mask for the channels\n    mask = torch.ones(num_channels, device=device)\n    mask[top_channels] = 0  # Zero out top channels\n    \n    # Define forward hook to zero out channels\n    def channel_ablation_hook(module, input, output):\n        return output * mask.view(1, -1, 1, 1)\n    \n    # Register hook and evaluate\n    hook = conv_layer.register_forward_hook(channel_ablation_hook)\n    ablated_acc = evaluate_model(model)\n    hook.remove()\n    \n    return ablated_acc, top_channels\n\n\n\nresults = {}\nprint(\"\\nStarting layer-wise analysis...\")\n\n\nimportance_scores_all = compute_all_feature_importance()\n\n# ablation for each layer\nfor layer_name, conv_layer in conv_layers.items():\n    print(f\"\\nAnalyzing {layer_name}\")\n    \n    ablated_acc, bottom_channels = ablate_channels(\n        model, \n        layer_name, \n        conv_layer, \n        importance_scores_all[layer_name]\n    )   \n\n    results[layer_name] = {\n        'importance_scores': importance_scores_all[layer_name],\n        'ablated_accuracy': ablated_acc,\n        'accuracy_drop': baseline_acc - ablated_acc,\n        'bottom_channels': bottom_channels\n    }\n    \n    print(f\"Original Accuracy: {baseline_acc:.2f}%\")\n    print(f\"Accuracy after ablating {layer_name}: {ablated_acc:.2f}%\")\n    print(f\"Accuracy drop: {baseline_acc - ablated_acc:.2f}%\")\n    print(f\"Bottom channels ablated: {bottom_channels}\")\n\n\nfor hook in hooks:\n    hook.remove()\n\n# Plotting\nplt.figure(figsize=(15, 10))\n\n# 1. Accuracy drops\nplt.subplot(2, 1, 1)\nlayer_names = list(results.keys())\nacc_drops = [results[name]['accuracy_drop'] for name in layer_names]\nplt.bar(range(len(layer_names)), acc_drops)\nplt.xticks(range(len(layer_names)), layer_names, rotation=45, ha='right')\nplt.title('Accuracy Drop After Channel Ablation')\nplt.ylabel('Accuracy Drop (%)')\nplt.grid(True)\n\n# 2. Channel importance distributions\nplt.subplot(2, 1, 2)\nfor name in layer_names[:5]:  \n    scores = results[name]['importance_scores']\n    plt.plot(np.sort(scores)[::-1], label=name)\nplt.title('Channel Importance Distribution')\nplt.xlabel('Channel Index (sorted)')\nplt.ylabel('Importance Score')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n=\nprint(\"\\nSummary of results:\")\nfor layer_name in results:\n    print(f\"\\n{layer_name}:\")\n    print(f\"Accuracy drop: {results[layer_name]['accuracy_drop']:.2f}%\")\n    print(f\"Number of channels ablated: {len(results[layer_name]['bottom_channels'])}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}